"""NMPC controller utilities for CARLA evaluation.

This module provides a lightweight nonlinear MPC setup around a kinematic
bicycle model. It is intentionally self contained so it can run inside the
existing evaluation script without additional solver dependencies.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import List, Sequence, Tuple
import math
import numpy as np


@dataclass
class VehicleState:
    """Compact representation of vehicle pose and speed."""

    x: float
    y: float
    yaw: float
    speed: float


@dataclass
class PolicyReference:
    """Short-horizon target generated by the learned policy."""

    target_speed: float
    nominal_steer: float


@dataclass
class NMPCConfig:
    horizon: int = 10
    dt: float = 0.1
    wheel_base: float = 2.8
    max_steer: float = math.radians(35)
    max_accel: float = 3.0
    max_decel: float = -5.0
    max_speed: float = 25.0
    lane_weight: float = 2.5
    speed_weight: float = 1.2
    steer_smooth_weight: float = 0.2
    accel_smooth_weight: float = 0.15


@dataclass
class NMPCResult:
    control_sequence: np.ndarray
    predicted_states: np.ndarray
    success: bool
    status: str
    tracking_errors: List[float]


class PIDController:
    def __init__(self, kp: float, ki: float, kd: float, clamp: Tuple[float, float]):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        self.integral = 0.0
        self.prev_error = 0.0
        self.clamp = clamp

    def reset(self):
        self.integral = 0.0
        self.prev_error = 0.0

    def compute(self, error: float, dt: float) -> float:
        self.integral += error * dt
        derivative = (error - self.prev_error) / dt if dt > 0 else 0.0
        output = self.kp * error + self.ki * self.integral + self.kd * derivative
        self.prev_error = error
        return float(np.clip(output, self.clamp[0], self.clamp[1]))


class NMPCController:
    """Lightweight NMPC controller using a kinematic bicycle model.

    The controller performs sequential linearization over the horizon and
    solves a regularized least-squares problem to produce steer/acceleration
    inputs while respecting simple bounds. It intentionally avoids heavy
    dependencies so it can run inside the evaluation loop.
    """

    def __init__(self, config: NMPCConfig):
        self.config = config
        self.last_control = np.zeros(2)  # accel, steer

    @staticmethod
    def wrap_angle(angle: float) -> float:
        """Normalize an angle to [-pi, pi]."""

        return (angle + math.pi) % (2 * math.pi) - math.pi

    def convert_policy_output(self, action: np.ndarray, current_speed: float) -> PolicyReference:
        """Convert PPO policy output to NMPC reference values."""

        throttle, steer, brake = float(action[0]), float(action[1]), float(action[2])
        target_speed = np.clip(
            current_speed + throttle * 3.0 - brake * 5.0,
            0.0,
            self.config.max_speed,
        )
        nominal_steer = float(np.clip(steer, -self.config.max_steer, self.config.max_steer))
        return PolicyReference(target_speed=target_speed, nominal_steer=nominal_steer)

    def simulate_dynamics(
        self, state: VehicleState, control: Sequence[float]
    ) -> VehicleState:
        accel, steer = control
        steer = float(np.clip(steer, -self.config.max_steer, self.config.max_steer))
        accel = float(np.clip(accel, self.config.max_decel, self.config.max_accel))
        v = np.clip(state.speed + accel * self.config.dt, 0.0, self.config.max_speed)
        yaw_rate = v / self.config.wheel_base * math.tan(steer)
        yaw = state.yaw + yaw_rate * self.config.dt
        x = state.x + v * math.cos(yaw) * self.config.dt
        y = state.y + v * math.sin(yaw) * self.config.dt
        return VehicleState(x=x, y=y, yaw=self.wrap_angle(yaw), speed=v)

    def plan(
        self,
        initial_state: VehicleState,
        waypoints: Sequence[Tuple[float, float, float]],
        policy_ref: PolicyReference,
    ) -> NMPCResult:
        if len(waypoints) == 0:
            return NMPCResult(
                control_sequence=np.zeros((self.config.horizon, 2)),
                predicted_states=np.zeros((self.config.horizon + 1, 4)),
                success=False,
                status="no_waypoints",
                tracking_errors=[],
            )

        accel_ref = np.clip(
            (policy_ref.target_speed - initial_state.speed) / max(self.config.dt, 1e-3),
            self.config.max_decel,
            self.config.max_accel,
        )
        control_guess = np.tile(
            np.array([accel_ref, policy_ref.nominal_steer]), (self.config.horizon, 1)
        )

        states = [initial_state]
        tracking_errors: List[float] = []

        for k in range(self.config.horizon):
            idx = min(k, len(waypoints) - 1)
            target_x, target_y, target_yaw = waypoints[idx]
            state_k = states[-1]
            cross_track = math.hypot(target_x - state_k.x, target_y - state_k.y)
            heading_error = self.wrap_angle(target_yaw - state_k.yaw)
            tracking_errors.append(cross_track)

            accel_term = (
                self.config.speed_weight * (policy_ref.target_speed - state_k.speed)
            )
            steer_term = heading_error * self.config.lane_weight + policy_ref.nominal_steer

            accel = 0.5 * control_guess[k, 0] + 0.5 * accel_term
            steer = 0.5 * control_guess[k, 1] + 0.5 * steer_term

            if k > 0:
                accel += self.config.accel_smooth_weight * (
                    control_guess[k - 1, 0] - control_guess[k, 0]
                )
                steer += self.config.steer_smooth_weight * (
                    control_guess[k - 1, 1] - control_guess[k, 1]
                )

            accel = float(np.clip(accel, self.config.max_decel, self.config.max_accel))
            steer = float(np.clip(steer, -self.config.max_steer, self.config.max_steer))
            control_guess[k] = np.array([accel, steer])
            states.append(self.simulate_dynamics(state_k, control_guess[k]))

        predicted = np.array([[s.x, s.y, s.yaw, s.speed] for s in states])
        return NMPCResult(
            control_sequence=control_guess,
            predicted_states=predicted,
            success=True,
            status="ok",
            tracking_errors=tracking_errors,
        )

    def to_control_action(self, optimal: NMPCResult) -> np.ndarray:
        accel, steer = optimal.control_sequence[0]
        throttle = np.clip(accel, 0.0, self.config.max_accel) / self.config.max_accel
        brake = np.clip(-accel, 0.0, -self.config.max_decel) / -self.config.max_decel
        self.last_control = np.array([accel, steer])
        return np.array([throttle, steer / self.config.max_steer, brake], dtype=np.float32)


def extract_waypoints_from_queue(
    queue_like: Sequence[Tuple[object, object]], max_points: int
) -> List[Tuple[float, float, float]]:
    """Utility to convert CARLA waypoint queue into tuples.

    The BasicAgent keeps a queue of ``(carla.Waypoint, RoadOption)`` pairs. To
    keep the NMPC code decoupled from the CARLA API we only access the fields we
    need and fall back gracefully if they are missing.
    """

    waypoints: List[Tuple[float, float, float]] = []
    for waypoint_data in list(queue_like)[:max_points]:
        waypoint = waypoint_data[0]
        if hasattr(waypoint, "transform"):
            wp_transform = waypoint.transform
            location = getattr(wp_transform, "location", None)
            rotation = getattr(wp_transform, "rotation", None)
            if location is not None and rotation is not None:
                waypoints.append(
                    (
                        float(location.x),
                        float(location.y),
                        math.radians(float(rotation.yaw)),
                    )
                )
    return waypoints
